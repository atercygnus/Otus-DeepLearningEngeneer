{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'C:\\\\associative_represenations_data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('tfeats.pkl', 'rb')\n",
    "tfeats = pickle.load(f)\n",
    "    \n",
    "f = open('vfeats.pkl', 'rb')\n",
    "vfeats = pickle.load(f)\n",
    "\n",
    "f = open('tcapts.pkl', 'rb')\n",
    "tcapts = pickle.load(f)\n",
    "    \n",
    "f = open('vcapts.pkl', 'rb')\n",
    "vcapts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118287, 2048)\n",
      "(5000, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(tfeats.shape)\n",
    "print(vfeats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118287, 5)\n",
      "(5000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(tcapts.shape)\n",
    "print(vcapts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['A man is in a funny position during a tennis match',\n",
       "        'A tennis player at the net after his play on the court. ',\n",
       "        'A man near the net playing tennis with official looking on.',\n",
       "        'a man by a tennis net getting ready to hit a ball',\n",
       "        'A man is attempting to return the ball'],\n",
       "       ['A white van is following an orange and white bus down the road. ',\n",
       "        'A van following behind a bus in the street. ',\n",
       "        'A white and orange bus driving down a city street.',\n",
       "        'A van follows behind a bus on a rural road.',\n",
       "        'A passenger bus that is driving down a street.'],\n",
       "       ['A group of children sitting around each other.',\n",
       "        'four children looking at each other one holding long object',\n",
       "        'A girl holding a tube talking to another girl.',\n",
       "        'Group of children sitting on a bench petting a dog.',\n",
       "        'The children are grouped together waiting their turn.'],\n",
       "       ...,\n",
       "       ['the elephants are  all next to each other under the tree',\n",
       "        'Several elephants standing in the shade of a tree.',\n",
       "        'Some very cute elephants in a grassy area.',\n",
       "        'Several elephants can be seen huddled together in the brush.',\n",
       "        'A few black elephants are out in the wild together. '],\n",
       "       ['A large industrial range in a kitchen with other small appliances.',\n",
       "        'a kitchen with a stove a coffee maker and a shelf',\n",
       "        'Large dirty stove in green and brown kitchen.',\n",
       "        'A kitchen with two ranges and an industrial coffee maker.  ',\n",
       "        'A kitchen area with stoves, shelves and a coffee maker.'],\n",
       "       ['Stuffed toy bears hanging on netting at indoor event.',\n",
       "        'Two teddy bears are attached to the net.',\n",
       "        'Teddy bears hanging from  a net near an HSBC sign.',\n",
       "        'Teddy bears home in front of an ice rink. ',\n",
       "        'A couple of brown teddy bears hanging from a metal fence.']],\n",
       "      dtype='<U250')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcapts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = \"#PAD#\"\n",
    "UNK = \"#UNK#\"\n",
    "START = \"#START#\"\n",
    "END = \"#END#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split sentence into tokens (split into lowercased words)\n",
    "def split_sentence(sentence):\n",
    "    return list(filter(lambda x: len(x) > 0, re.split('\\W+', sentence.lower())))\n",
    "\n",
    "def generate_vocabulary(train_captions):\n",
    "\n",
    "    w_bag = [PAD, START, UNK, END] + [item.lower() for sublist in [split_sentence(sent) for sent in train_captions] for item in sublist]\n",
    "    vocab = Counter(w_bag)\n",
    "    vocab = [PAD, START, UNK, END] + [token for token, cnt in zip(vocab.keys(), vocab.values()) if cnt >= 5]\n",
    "    vocab = {key: i for i, key in enumerate(vocab)}\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def caption_tokens_to_indices(captions, vocab):\n",
    "    return  [[vocab[START]] + [vocab[word] if word in vocab else vocab[UNK] for word in split_sentence(capt)] + [vocab[END]] for capt in captions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5154\n"
     ]
    }
   ],
   "source": [
    "# prepare vocabulary\n",
    "vocab = generate_vocabulary(tcapts[:, 3])\n",
    "vocab_inverse = {idx: w for w, idx in vocab.items()}\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use this during training\n",
    "def batch_captions_to_matrix(batch_captions, pad_idx, max_len=None):\n",
    "    \n",
    "    if max_len is None:\n",
    "        pad_len = max(map(len, batch_captions))\n",
    "    else:\n",
    "        pad_len = min(max(map(len, batch_captions)), max_len)\n",
    "        \n",
    "    matrix = []\n",
    "    for capt in batch_captions:\n",
    "        if pad_len-len(capt) >= 0:\n",
    "            matrix.append(np.pad(capt, (0, pad_len-len(capt)), mode='constant', constant_values=pad_idx))\n",
    "        else:\n",
    "            matrix.append(capt[:pad_len])\n",
    "    \n",
    "    return np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_captions(out):\n",
    "    softmax = nn.Softmax(dim=1)(out).argmax(axis=1)\n",
    "    softmax_to_tokens = lambda batch: np.array(list(map(lambda token: vocab_inverse[token], batch.numpy().reshape(-1)))).reshape(*batch.shape)\n",
    "    return softmax_to_tokens(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = generate_vocabulary(tcapts[:, 3])\n",
    "tcapts_enc = batch_captions_to_matrix(caption_tokens_to_indices(tcapts[:, 3], vocab), vocab[PAD], max_len=50)\n",
    "vcapts_enc = batch_captions_to_matrix(caption_tokens_to_indices(vcapts[:, 3], vocab), vocab[PAD], max_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcapts_len = [len(x) for x in caption_tokens_to_indices(tcapts[:, 3], vocab)]\n",
    "vcapts_len = [len(x) for x in caption_tokens_to_indices(vcapts[:, 3], vocab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118287, 49)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcapts_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tcapts_encoded.pkl', 'wb') as file_embeds:\n",
    "    pickle.dump(tcapts_enc, file_embeds)\n",
    "    \n",
    "with open('vcapts_encoded.pkl', 'wb') as file_capts:\n",
    "    pickle.dump(vcapts_enc, file_capts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    IMG_EMBED_SIZE = tfeats.shape[1]\n",
    "    IMG_EMBED_BOTTLENECK = 120\n",
    "    WORD_EMBED_SIZE = 100\n",
    "    LSTM_UNITS = 300\n",
    "    LOGIT_BOTTLENECK = 120\n",
    "    pad_idx = vocab[PAD]\n",
    "\n",
    "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
    "        \n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "        self.img_embed_to_bottleneck = nn.Linear(self.IMG_EMBED_SIZE, self.IMG_EMBED_BOTTLENECK)\n",
    "        self.img_embed_bottleneck_to_h0 = nn.Linear(self.IMG_EMBED_BOTTLENECK, nhid)\n",
    "        \n",
    "        self.embedding = nn.Embedding(ntoken, ninp)\n",
    "        \n",
    "        if rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout)\n",
    "        elif rnn_type == 'GRU':\n",
    "            self.rnn = nn.GRU(ninp, nhid, nlayers, dropout=dropout)\n",
    "            \n",
    "        self.token_logits_bottleneck = nn.Linear(nhid, self.LOGIT_BOTTLENECK)\n",
    "        self.token_logits = nn.Linear(self.LOGIT_BOTTLENECK, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "    def init_weights(self):\n",
    "        \n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.img_embed_to_bottleneck.bias.data.fill_(0)\n",
    "        self.img_embed_to_bottleneck.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.img_embed_bottleneck_to_h0.bias.data.fill_(0)\n",
    "        self.img_embed_bottleneck_to_h0.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.token_logits_bottleneck.bias.data.fill_(0)\n",
    "        self.token_logits_bottleneck.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.token_logits.bias.data.fill_(0)\n",
    "        self.token_logits.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, x, input_lengths, hidden=None):\n",
    "        hidden = self.img_embed_bottleneck_to_h0(self.img_embed_to_bottleneck(hidden))\n",
    "        \n",
    "        word_embeds = self.drop(self.embedding(x.T))\n",
    "        word_embeds = nn.utils.rnn.pack_padded_sequence(word_embeds, batch_len, enforce_sorted=False)\n",
    "        \n",
    "        output, hidden = self.rnn(word_embeds, (hidden, hidden))\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(output, total_length=x.shape[1])\n",
    "        output = self.drop(output)\n",
    "\n",
    "        output_bottleneck = self.token_logits_bottleneck(output.view(output.shape[0]*output.shape[1], output.shape[2]))\n",
    "        output = self.token_logits(output_bottleneck)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new(self.nlayers, bsz, self.nhid).zero_(),\n",
    "                    weight.new(self.nlayers, bsz, self.nhid).zero_())\n",
    "        else:\n",
    "            return weight.new(self.nlayers, bsz, self.nhid).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "decoder = RNNModel('LSTM', ntoken=len(vocab), ninp=RNNModel.WORD_EMBED_SIZE, nhid=RNNModel.LSTM_UNITS, nlayers=1, dropout=0.3).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "Batch 100: loss: 5.249606609344482\n",
      "Batch 200: loss: 1.9148378372192383\n",
      "Batch 300: loss: 1.8509377241134644\n",
      "Batch 400: loss: 1.7441773414611816\n",
      "Batch 500: loss: 1.8146336078643799\n",
      "Batch 600: loss: 1.7934309244155884\n",
      "Batch 700: loss: 1.7180540561676025\n",
      "Batch 800: loss: 1.8004348278045654\n",
      "Batch 900: loss: 1.8061316013336182\n",
      "Batch 1000: loss: 1.8162428140640259\n",
      "Batch 1100: loss: 1.7713053226470947\n",
      "Batch 1200: loss: 1.8517801761627197\n",
      "Batch 1300: loss: 1.8685294389724731\n",
      "Batch 1400: loss: 1.9520533084869385\n",
      "Batch 1500: loss: 1.7668880224227905\n",
      "Batch 1600: loss: 1.7999995946884155\n",
      "Batch 1700: loss: 1.835193395614624\n",
      "Batch 1800: loss: 1.7093985080718994\n",
      "Batch 1900: loss: 1.7847278118133545\n",
      "Batch 2000: loss: 1.8700073957443237\n",
      "Batch 2100: loss: 1.8455947637557983\n",
      "Batch 2200: loss: 1.7625147104263306\n",
      "Batch 2300: loss: 1.7297617197036743\n",
      "Batch 2400: loss: 1.7644435167312622\n",
      "Batch 2500: loss: 1.7758479118347168\n",
      "Batch 2600: loss: 1.7405884265899658\n",
      "Batch 2700: loss: 1.7635899782180786\n",
      "Batch 2800: loss: 1.7360337972640991\n",
      "Batch 2900: loss: 1.8477660417556763\n",
      "Batch 3000: loss: 1.7758780717849731\n",
      "Batch 3100: loss: 1.7653560638427734\n",
      "Batch 3200: loss: 1.7593941688537598\n",
      "Batch 3300: loss: 1.748454213142395\n",
      "Batch 3400: loss: 1.7425581216812134\n",
      "Batch 3500: loss: 1.842827320098877\n",
      "Batch 3600: loss: 1.77008056640625\n",
      "EPOCH 2\n",
      "Batch 100: loss: 1.7974201440811157\n",
      "Batch 200: loss: 1.8488514423370361\n",
      "Batch 300: loss: 1.8313108682632446\n",
      "Batch 400: loss: 1.7253559827804565\n",
      "Batch 500: loss: 1.7978088855743408\n",
      "Batch 600: loss: 1.7848361730575562\n",
      "Batch 700: loss: 1.7127023935317993\n",
      "Batch 800: loss: 1.7976884841918945\n",
      "Batch 900: loss: 1.8031651973724365\n",
      "Batch 1000: loss: 1.8125413656234741\n",
      "Batch 1100: loss: 1.7713899612426758\n",
      "Batch 1200: loss: 1.8412768840789795\n",
      "Batch 1300: loss: 1.868251919746399\n",
      "Batch 1400: loss: 1.9493508338928223\n",
      "Batch 1500: loss: 1.7618464231491089\n",
      "Batch 1600: loss: 1.795922875404358\n",
      "Batch 1700: loss: 1.8313188552856445\n",
      "Batch 1800: loss: 1.7070724964141846\n",
      "Batch 1900: loss: 1.7861090898513794\n",
      "Batch 2000: loss: 1.8695766925811768\n",
      "Batch 2100: loss: 1.8461257219314575\n",
      "Batch 2200: loss: 1.7604531049728394\n",
      "Batch 2300: loss: 1.7299026250839233\n",
      "Batch 2400: loss: 1.7629303932189941\n",
      "Batch 2500: loss: 1.773038387298584\n",
      "Batch 2600: loss: 1.739737629890442\n",
      "Batch 2700: loss: 1.7615172863006592\n",
      "Batch 2800: loss: 1.7303516864776611\n",
      "Batch 2900: loss: 1.8472143411636353\n",
      "Batch 3000: loss: 1.7731965780258179\n",
      "Batch 3100: loss: 1.763809084892273\n",
      "Batch 3200: loss: 1.7590537071228027\n",
      "Batch 3300: loss: 1.7472100257873535\n",
      "Batch 3400: loss: 1.7404615879058838\n",
      "Batch 3500: loss: 1.8438475131988525\n",
      "Batch 3600: loss: 1.769258975982666\n",
      "EPOCH 3\n",
      "Batch 100: loss: 1.7959232330322266\n",
      "Batch 200: loss: 1.8455888032913208\n",
      "Batch 300: loss: 1.8262884616851807\n",
      "Batch 400: loss: 1.7230855226516724\n",
      "Batch 500: loss: 1.7962465286254883\n",
      "Batch 600: loss: 1.7856621742248535\n",
      "Batch 700: loss: 1.723750114440918\n",
      "Batch 800: loss: 1.7981631755828857\n",
      "Batch 900: loss: 1.803367018699646\n",
      "Batch 1000: loss: 1.808940052986145\n",
      "Batch 1100: loss: 1.7672241926193237\n",
      "Batch 1200: loss: 1.8384943008422852\n",
      "Batch 1300: loss: 1.8695170879364014\n",
      "Batch 1400: loss: 1.9486252069473267\n",
      "Batch 1500: loss: 1.755599856376648\n",
      "Batch 1600: loss: 1.791141152381897\n",
      "Batch 1700: loss: 1.8257960081100464\n",
      "Batch 1800: loss: 1.7053556442260742\n",
      "Batch 1900: loss: 1.7867414951324463\n",
      "Batch 2000: loss: 1.8645172119140625\n",
      "Batch 2100: loss: 1.8429025411605835\n",
      "Batch 2200: loss: 1.756134033203125\n",
      "Batch 2300: loss: 1.7313816547393799\n",
      "Batch 2400: loss: 1.762763500213623\n",
      "Batch 2500: loss: 1.7713735103607178\n",
      "Batch 2600: loss: 1.7348841428756714\n",
      "Batch 2700: loss: 1.7572808265686035\n",
      "Batch 2800: loss: 1.7296621799468994\n",
      "Batch 2900: loss: 1.8481817245483398\n",
      "Batch 3000: loss: 1.7690753936767578\n",
      "Batch 3100: loss: 1.7618378400802612\n",
      "Batch 3200: loss: 1.7611491680145264\n",
      "Batch 3300: loss: 1.7443175315856934\n",
      "Batch 3400: loss: 1.7385694980621338\n",
      "Batch 3500: loss: 1.8431453704833984\n",
      "Batch 3600: loss: 1.766206979751587\n",
      "EPOCH 4\n",
      "Batch 100: loss: 1.7937830686569214\n",
      "Batch 200: loss: 1.843224048614502\n",
      "Batch 300: loss: 1.8187702894210815\n",
      "Batch 400: loss: 1.7235397100448608\n",
      "Batch 500: loss: 1.792273998260498\n",
      "Batch 600: loss: 1.7889580726623535\n",
      "Batch 700: loss: 1.7120023965835571\n",
      "Batch 800: loss: 1.7954858541488647\n",
      "Batch 900: loss: 1.8020390272140503\n",
      "Batch 1000: loss: 1.80961012840271\n",
      "Batch 1100: loss: 1.7660934925079346\n",
      "Batch 1200: loss: 1.8372628688812256\n",
      "Batch 1300: loss: 1.864715576171875\n",
      "Batch 1400: loss: 1.9440466165542603\n",
      "Batch 1500: loss: 1.7512198686599731\n",
      "Batch 1600: loss: 1.787535548210144\n",
      "Batch 1700: loss: 1.823907494544983\n",
      "Batch 1800: loss: 1.7062979936599731\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-0d8184691b8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Batch {}: loss: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "images_count = tcapts.shape[0]\n",
    "BATCH_SIZE = 32\n",
    "BATCH_COUNT = int(np.ceil(images_count/BATCH_SIZE))\n",
    "\n",
    "EVERY_BATCHES_TOSHOW = 100\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "decoder.train()\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "\n",
    "    print('EPOCH %d' % (e+1))\n",
    "\n",
    "    for i in range(BATCH_COUNT):\n",
    "        capts = tcapts_enc[i*BATCH_SIZE:(i+1)*BATCH_SIZE, :]\n",
    "        target = torch.Tensor(np.hstack((capts, np.array([vocab[PAD]]*capts.shape[0]).reshape(-1, 1)))[:, 1:]).long()\n",
    "        im_feats = tfeats[i*BATCH_SIZE:(i+1)*BATCH_SIZE, :]\n",
    "\n",
    "        batch_len = tcapts_len[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "\n",
    "        capts = torch.Tensor(capts).long()\n",
    "        im_feats = torch.Tensor(np.expand_dims(im_feats, 0))\n",
    "\n",
    "        decoder.zero_grad()\n",
    "\n",
    "        out, hidden = decoder(capts.cuda(), batch_len, im_feats.cuda())\n",
    "        loss = criterion(out, target.view(-1).cuda())\n",
    "\n",
    "        if i > 0 and i % EVERY_BATCHES_TOSHOW == 0:\n",
    "            print(\"Batch {}: loss: {}\".format(i, loss.cpu().detach().numpy()))\n",
    "\n",
    "        loss.backward()        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(tcapts_enc[:30, :]).long().cuda()\n",
    "batch_len = tcapts_len[:30]\n",
    "hidden = torch.Tensor(np.expand_dims(tfeats[:30, :], 0)).cuda()\n",
    "\n",
    "decoder.eval()\n",
    "\n",
    "out, hid = decoder(x, batch_len, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... и тут что-то пошло не так( у нас одни паддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'#PAD#': 1470})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(decode_captions(out.detach().cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... а попытка сделать инференс вообще ломает куду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[vocab[START]]]).long()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2048])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = np.expand_dims(tfeats[0], 0)\n",
    "hidden = np.expand_dims(hidden, 0)\n",
    "hidden = torch.tensor(hidden)\n",
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tabulate: failed to synchronize: cudaErrorAssert: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-331931e0271c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-4fcd68190fc2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, input_lengths, hidden)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mword_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mword_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[1;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data, batch_sizes, sorted_indices, unsorted_indices)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# should only be used internally.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0munsorted_indices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minvert_permutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;31m# support being called as `PackedSequence(data, batch_sizes, sorted_indices)`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36minvert_permutation\u001b[1;34m(permutation)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     output.scatter_(0, permutation,\n\u001b[1;32m--> 230\u001b[1;33m                     torch.arange(0, permutation.numel(), device=permutation.device))\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tabulate: failed to synchronize: cudaErrorAssert: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "decoder(x.cuda(), [1], hidden.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
